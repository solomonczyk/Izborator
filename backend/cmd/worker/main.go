package main

import (
	"context"
	"flag"
	"log"
	"os"
	"os/signal"
	"syscall"
	"time"

	"github.com/solomonczyk/izborator/internal/config"
	"github.com/solomonczyk/izborator/internal/logger"
	"github.com/solomonczyk/izborator/internal/scraper"
	"github.com/solomonczyk/izborator/internal/storage"
)

func main() {
	// –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
	cfg, err := config.Load()
	if err != nil {
		log.Fatalf("Failed to load config: %v", err)
	}

	// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞
	logger := logger.New(cfg.LogLevel)

	// –§–ª–∞–≥–∏ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
	testURL := flag.String("url", "", "URL —Ç–æ–≤–∞—Ä–∞ –¥–ª—è —Ç–µ—Å—Ç–∞")
	shopIDStr := flag.String("shop", "a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11", "UUID –º–∞–≥–∞–∑–∏–Ω–∞")
	flag.Parse()

	ctx := context.Background()

	// –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
	logger.Info("Connecting to PostgreSQL", map[string]interface{}{
		"host":     cfg.DB.Host,
		"port":      cfg.DB.Port,
		"user":      cfg.DB.User,
		"database":  cfg.DB.Database,
		"dsn":       cfg.DB.DSN(),
	})
	pg, err := storage.NewPostgres(&cfg.DB, logger)
	if err != nil {
		logger.Fatal("Failed to connect to PostgreSQL", map[string]interface{}{"error": err.Error(), "dsn": cfg.DB.DSN()})
	}
	defer pg.Close()

	// –°–æ–∑–¥–∞–Ω–∏–µ –∞–¥–∞–ø—Ç–µ—Ä–æ–≤
	scraperStorage := storage.NewScraperAdapter(pg)

	// –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–æ–≤ (queue –ø–æ–∫–∞ nil, —Ç–∞–∫ –∫–∞–∫ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω)
	scraperService := scraper.New(scraperStorage, nil, logger)

	// –†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ–¥–Ω–æ–≥–æ URL
	if *testURL != "" {
		logger.Info("üöÄ Starting manual test scrape...", map[string]interface{}{
			"url":     *testURL,
			"shop_id": *shopIDStr,
		})

		// –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ –º–∞–≥–∞–∑–∏–Ω–∞
		shopConfig, err := scraperStorage.GetShopConfig(*shopIDStr)
		if err != nil {
			logger.Fatal("Shop config not found", map[string]interface{}{
				"error":  err,
				"shop_id": *shopIDStr,
			})
		}

		logger.Info("Shop config loaded", map[string]interface{}{
			"shop_name": shopConfig.Name,
			"base_url":  shopConfig.BaseURL,
		})

		// –ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä
		rawProduct, err := scraperService.ParseProduct(ctx, *testURL, shopConfig)
		if err != nil {
			logger.Fatal("‚ùå Scraping failed", map[string]interface{}{
				"error": err.Error(),
				"url":   *testURL,
			})
		}

		logger.Info("‚úÖ SUCCESS! Product parsed", map[string]interface{}{
			"name":     rawProduct.Name,
			"price":    rawProduct.Price,
			"currency": rawProduct.Currency,
			"brand":    rawProduct.Brand,
			"category": rawProduct.Category,
		})

		// –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
		if err := scraperService.SaveRawProduct(ctx, rawProduct); err != nil {
			logger.Error("Failed to save raw product", map[string]interface{}{
				"error": err.Error(),
			})
		} else {
			logger.Info("üíæ Saved to raw_products table", map[string]interface{}{})
		}

		return
	}

	// –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º –≤–æ—Ä–∫–µ—Ä–∞ (–æ–∂–∏–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á –∏–∑ –æ—á–µ—Ä–µ–¥–∏)
	logger.Info("Worker started (waiting for jobs...) - use -url to test scrape", map[string]interface{}{})

	// Graceful shutdown
	quit := make(chan os.Signal, 1)
	signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
	<-quit

	logger.Info("Shutting down worker...", map[string]interface{}{})

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	// TODO: Graceful shutdown –≤–æ—Ä–∫–µ—Ä–æ–≤
	_ = ctx

	logger.Info("Worker exited", map[string]interface{}{})
}
